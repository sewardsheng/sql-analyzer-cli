import { beforeAll, afterAll, beforeEach, afterEach, vi } from 'vitest';
import { config } from './config/index.js';

// æ¨¡æ‹ŸLLMæœåŠ¡
vi.mock('./core/llm-service.js', () => {
  const mockLLMService = {
    call: vi.fn().mockImplementation(async (prompt: string, options?: any) => {
      // æ¨¡æ‹Ÿå»¶è¿Ÿ
      await new Promise(resolve => setTimeout(resolve, 100));

      // Catch-all: ç»Ÿä¸€ä¸ºæ‰€æœ‰LLMè°ƒç”¨è¿”å›è´¨é‡è¯„ä¼°ç»“æœ
      // ç¡®ä¿æµ‹è¯•ç¯å¢ƒä¸­çš„LLMè°ƒç”¨æ€»æ˜¯æˆåŠŸå¹¶è¿”å›85åˆ†

      if (prompt.includes('é‡å¤æ£€æµ‹') || prompt.includes('ç›¸ä¼¼æ€§')) {
        return {
          success: true,
          content: JSON.stringify({
            isDuplicate: false,
            similarity: 0.1,
            duplicateType: 'none',
            reason: 'è§„åˆ™å†…å®¹ä¸é‡å¤',
            confidence: 0.95,
            matchedRules: [],
            matchDetails: {}
          }),
          rawContent: JSON.stringify({
            isDuplicate: false,
            similarity: 0.1,
            duplicateType: 'none',
            reason: 'è§„åˆ™å†…å®¹ä¸é‡å¤',
            confidence: 0.95,
            matchedRules: [],
            matchDetails: {}
          }),
          usage: {
            prompt_tokens: 100,
            completion_tokens: 150,
            total_tokens: 250
          },
          duration: 800,
          model: 'gpt-3.5-turbo',
          timestamp: new Date().toISOString()
        };
      }

      // åŒ¹é…è´¨é‡è¯„ä¼°ç›¸å…³æç¤ºè¯
      if (prompt.includes('è´¨é‡è¯„ä¼°ä¸“å®¶') || prompt.includes('è¯„ä¼°ç”Ÿæˆçš„SQLè§„åˆ™') || prompt.includes('å®é™…å¯ç”¨æ€§') || prompt.includes('ä»»åŠ¡ç›®æ ‡') || prompt.includes('SQLè§„åˆ™è´¨é‡è¯„ä¼°ä¸“å®¶')) {
        return {
          success: true,
          content: JSON.stringify({
            qualityScore: 85,
            qualityLevel: "good",
            shouldKeep: true,
            dimensionScores: {
              accuracy: 90,
              completeness: 80,
              practicality: 85,
              generality: 85,
              consistency: 85
            },
            strengths: [
              "æ ¸å¿ƒæ€æƒ³æ­£ç¡®ï¼ŒæŠ“ä½äº†å…³é”®é—®é¢˜",
              "ç¤ºä¾‹æ¸…æ™°æ˜“æ‡‚",
              "è§„åˆ™å…·æœ‰å¾ˆé«˜çš„å®é™…åº”ç”¨ä»·å€¼"
            ],
            issues: [
              "å¯ä»¥è¿›ä¸€æ­¥ä¼˜åŒ–æè¿°",
              "å¢åŠ æ›´å¤šè¾¹ç•Œæƒ…å†µè¯´æ˜"
            ],
            recommendations: [
              "è¡¥å……æ›´è¯¦ç»†çš„æŠ€æœ¯ç»†èŠ‚",
              "å¢åŠ æ›´å¤šå®é™…åº”ç”¨åœºæ™¯"
            ],
            confidence: 0.9,
            summary: "è¯¥è§„åˆ™è´¨é‡è‰¯å¥½ï¼Œå…·æœ‰å®é™…åº”ç”¨ä»·å€¼ï¼Œå»ºè®®é‡‡çº³ä½¿ç”¨ã€‚"
          }),
          rawContent: JSON.stringify({
            qualityScore: 85,
            qualityLevel: "good",
            shouldKeep: true,
            dimensionScores: {
              accuracy: 90,
              completeness: 80,
              practicality: 85,
              generality: 85,
              consistency: 85
            }
          }),
          usage: {
            prompt_tokens: 150,
            completion_tokens: 200,
            total_tokens: 350
          },
          duration: 1200,
          model: 'gpt-3.5-turbo',
          timestamp: new Date().toISOString()
        };
      }

      // é»˜è®¤æƒ…å†µï¼šå¯¹äºå…¶ä»–æç¤ºè¯ï¼Œä¹Ÿè¿”å›è´¨é‡è¯„ä¼°ç»“æœï¼ˆå…œåº•æœºåˆ¶ï¼‰
      console.log('ğŸ” LLM mockæ”¶åˆ°æœªåŒ¹é…çš„æç¤ºè¯ï¼Œè¿”å›é»˜è®¤è´¨é‡è¯„ä¼°:', prompt.substring(0, 80) + '...');
      return {
        success: true,
        content: JSON.stringify({
          qualityScore: 85,
          qualityLevel: "good",
          shouldKeep: true,
          dimensionScores: {
            accuracy: 90,
            completeness: 80,
            practicality: 85,
            generality: 85,
            consistency: 85
          },
          strengths: ["é»˜è®¤ï¼šè§„åˆ™ç»“æ„å®Œæ•´"],
          issues: [],
          recommendations: [],
          confidence: 0.9,
          summary: "é»˜è®¤è´¨é‡è¯„ä¼°ï¼šè§„åˆ™åŸºæœ¬ç¬¦åˆè¦æ±‚ã€‚"
        }),
        rawContent: JSON.stringify({
          qualityScore: 85,
          qualityLevel: "good"
        }),
        usage: {
          prompt_tokens: 100,
          completion_tokens: 100,
          total_tokens: 200
        },
        duration: 800,
        model: 'gpt-3.5-turbo',
        timestamp: new Date().toISOString()
      };
    }),

    
    batchCall: vi.fn().mockImplementation(async (prompts: string[]) => {
      return Promise.all(prompts.map(prompt => mockLLMService.call(prompt)));
    }),

    setConfig: vi.fn(),
    getConfig: vi.fn().mockReturnValue({
      apiKey: 'test-key',
      model: 'gpt-3.5-turbo',
      temperature: 0.7,
      maxTokens: 4000
    })
  };

  return {
    LLMService: vi.fn().mockImplementation(() => mockLLMService),
    getLLMService: vi.fn().mockReturnValue(mockLLMService),
    llmService: mockLLMService,
    default: mockLLMService
  };
});

// æ¨¡æ‹ŸLangChain
vi.mock('@langchain/openai', () => ({
  ChatOpenAI: vi.fn().mockImplementation(() => ({
    invoke: vi.fn().mockResolvedValue({
      content: JSON.stringify({
        qualityScore: 85,
        qualityLevel: "good",
        shouldKeep: true,
        dimensionScores: {
          accuracy: 90,
          completeness: 80,
          practicality: 85,
          generality: 85,
          consistency: 85
        },
        confidence: 0.9,
        summary: "æ¨¡æ‹Ÿè¯„ä¼°ç»“æœ"
      })
    }),
    batch: vi.fn().mockResolvedValue([
      {
        content: JSON.stringify({
          qualityScore: 85,
          qualityLevel: "good",
          shouldKeep: true,
          dimensionScores: {
            accuracy: 90,
            completeness: 80,
            practicality: 85,
            generality: 85,
            consistency: 85
          },
          confidence: 0.9,
          summary: "æ¨¡æ‹Ÿè¯„ä¼°ç»“æœ"
        })
      }
    ])
  }))
}));

// æ¨¡æ‹Ÿæ–‡ä»¶ç³»ç»Ÿæ“ä½œ
vi.mock('fs', () => ({
  default: {
    readFileSync: vi.fn(),
    writeFileSync: vi.fn(),
    existsSync: vi.fn().mockReturnValue(true),
    readdirSync: vi.fn().mockReturnValue([]),
    statSync: vi.fn().mockReturnValue({
      isFile: () => true,
      isDirectory: () => false,
      size: 1024,
      mtime: new Date()
    }),
    mkdirSync: vi.fn(),
    rmSync: vi.fn()
  },
  readFileSync: vi.fn(),
  writeFileSync: vi.fn(),
  existsSync: vi.fn().mockReturnValue(true),
  readdirSync: vi.fn().mockReturnValue([]),
  statSync: vi.fn().mockReturnValue({
    isFile: () => true,
    isDirectory: () => false,
    size: 1024,
    mtime: new Date()
  }),
  mkdirSync: vi.fn(),
  rmSync: vi.fn()
}));

// æ¨¡æ‹ŸHTTPè¯·æ±‚
vi.mock('node-fetch', () => ({
  default: vi.fn().mockResolvedValue({
    ok: true,
    status: 200,
    json: () => Promise.resolve({
      success: true,
      data: {}
    })
  })
}));

// å…¨å±€æµ‹è¯•è®¾ç½®
beforeAll(async () => {
  // è®¾ç½®æµ‹è¯•ç¯å¢ƒå˜é‡
  process.env.NODE_ENV = 'test';
  process.env.LOG_LEVEL = 'silent';
  process.env.RULE_LEARNING_ENABLED = 'false'; // ç¦ç”¨è§„åˆ™å­¦ä¹ é¿å…LLMè°ƒç”¨
  process.env.LLM_API_KEY = 'test-key';
  process.env.LLM_MODEL = 'gpt-3.5-turbo';

  // é…ç½®æµ‹è¯•ç¯å¢ƒ
  config.set('ruleLearning.enabled', false);
  config.set('llm.mockMode', true);

  // è®¾ç½®æµ‹è¯•è¶…æ—¶
  vi.setConfig({
    testTimeout: 10000, // 10ç§’è¶…æ—¶
    hookTimeout: 10000
  });

  // ç¦ç”¨æ§åˆ¶å°è¾“å‡ºä»¥ä¿æŒæµ‹è¯•è¾“å‡ºæ¸…æ´
  global.console = {
    ...console,
    log: vi.fn(),
    info: vi.fn(),
    warn: vi.fn(),
    error: vi.fn(),
    debug: vi.fn(),
  };

  // æ·»åŠ å…¨å±€æµ‹è¯•å·¥å…·
  global.testUtils = {
    // åˆ›å»ºæ¨¡æ‹Ÿçš„è§„åˆ™ä¿¡æ¯
    createMockRule: (overrides = {}) => ({
      id: 'test-rule-1',
      title: 'æµ‹è¯•è§„åˆ™',
      description: 'è¿™æ˜¯ä¸€ä¸ªæµ‹è¯•è§„åˆ™',
      category: 'sql-security',
      severity: 'medium',
      sqlPattern: 'SELECT * FROM users',
      examples: { bad: ['SELECT *'], good: ['SELECT id, name'] },
      status: 'draft',
      createdAt: new Date('2024-01-01'),
      updatedAt: new Date('2024-01-01'),
      tags: ['test'],
      metadata: {},
      ...overrides
    }),

    // åˆ›å»ºæ¨¡æ‹Ÿçš„åˆ†æç»“æœ
    createMockAnalysisResult: (overrides = {}) => ({
      success: true,
      data: {
        summary: 'SQLåˆ†æå®Œæˆ',
        issues: [],
        recommendations: [],
        confidence: 0.85
      },
      metadata: {
        processingTime: 1000,
        databaseType: 'mysql'
      },
      ...overrides
    }),

    // åˆ›å»ºæ¨¡æ‹Ÿçš„è¯„ä¼°ç»“æœ
    createMockEvaluationResult: (overrides = {}) => ({
      isDuplicate: false,
      similarity: 0,
      duplicateType: 'none',
      reason: 'æ— é‡å¤',
      confidence: 0.9,
      matchedRules: [],
      matchDetails: {},
      ...overrides
    }),

    // ç­‰å¾…å¼‚æ­¥æ“ä½œ
    waitFor: (ms: number) => new Promise(resolve => setTimeout(resolve, ms)),

    // åˆ›å»ºæ–‡ä»¶ç³»ç»Ÿæ¨¡æ‹Ÿ
    createMockFileSystem: () => {
      const mockFs = {
        readFile: vi.fn(),
        writeFile: vi.fn(),
        exists: vi.fn(),
        readdir: vi.fn(),
        stat: vi.fn(),
        mkdir: vi.fn()
      };
      return mockFs;
    },

    // æ¨¡æ‹ŸLLMæœåŠ¡å“åº”
    createMockLLMResponse: (content: string) => ({
      success: true,
      content,
      rawContent: content,
      usage: {
        prompt_tokens: 100,
        completion_tokens: 200,
        total_tokens: 300
      },
      duration: 1500,
      model: 'gpt-3.5-turbo',
      timestamp: new Date().toISOString()
    })
  };

  // æ·»åŠ ç±»å‹å£°æ˜
  declare global {
    var testUtils: {
      createMockRule: (overrides?: any) => any;
      createMockAnalysisResult: (overrides?: any) => any;
      createMockEvaluationResult: (overrides?: any) => any;
      waitFor: (ms: number) => Promise<void>;
      createMockFileSystem: () => any;
      createMockLLMResponse: (content: string) => any;
    };
  }
});

afterAll(async () => {
  // æ¸…ç†æµ‹è¯•ç¯å¢ƒ
  delete process.env.NODE_ENV;
  delete process.env.LOG_LEVEL;
  delete process.env.RULE_LEARNING_ENABLED;
  delete process.env.LLM_API_KEY;
  delete process.env.LLM_MODEL;

  // æ¢å¤console
  global.console = console;
  delete global.testUtils;

  // æ¸…ç†æ‰€æœ‰æ¨¡æ‹Ÿ
  vi.unmockAll?.();
});

beforeEach(() => {
  // æ¯ä¸ªæµ‹è¯•å‰çš„æ¸…ç†
  vi.clearAllMocks();

  // é‡ç½®é…ç½®
  config.set('ruleLearning.enabled', false);
  config.set('llm.mockMode', true);
});

afterEach(() => {
  // æ¯ä¸ªæµ‹è¯•åçš„æ¸…ç†
  vi.restoreAllMocks();

  // æ¸…ç†å®šæ—¶å™¨
  vi.clearAllTimers();

  // æ¸…ç†äº‹ä»¶ç›‘å¬å™¨
  process.removeAllListeners();
});